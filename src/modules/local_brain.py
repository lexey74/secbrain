"""
LocalBrain - –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM (Ollama)
"""
from typing import Dict, List, Optional
import json


class LocalBrain:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Ollama"""
    
    SYSTEM_PROMPT = """Role: You are a Librarian for a personal Knowledge Base.

Input Data:
1. Post Text & Author
2. Video Transcript (with timestamps)
3. User Comments
4. KNOWN TAGS LIST: [{known_tags}]

Tasks:
1. Analyze: Understand the core meaning of the content.

2. Tagging (Priority):
   - Check the KNOWN TAGS LIST first. If a tag fits, USE IT. Do not create synonyms (e.g., if 'coding' exists, do not create 'programming').
   - Create NEW tags only if the topic is completely new.
   - Format: English, lowercase, snake_case.
   - Limit: Max 15 tags total.

3. Categorize: Choose ONE Category (Tutorial, Opinion, News, Life, Humor).

4. Summary: Create a concise bullet-point summary (3-5 points) in Russian. Use timestamps [MM:SS] if referring to video parts.

5. Filter Comments: Keep ONLY comments that add value (critique, personal experience, alternative tools). Remove generic praise ("cool", "thanks").

Output: strictly JSON.
{
  "summary": "markdown string with bullet points",
  "category": "string",
  "tags": ["tag1", "tag2"],
  "valuable_comments": ["user: text", "user: text"]
}
"""
    
    def __init__(self, model: str = "llama3.2", base_url: str = "http://localhost:11434"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama
            base_url: URL Ollama —Å–µ—Ä–≤–µ—Ä–∞
        """
        self.model = model
        self.base_url = base_url
        self.client = None
    
    def initialize(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Ollama"""
        try:
            import ollama
            self.client = ollama.Client(host=self.base_url)
            
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            try:
                print(f"‚úÖ Ollama –ø–æ–¥–∫–ª—é—á–µ–Ω: {self.model}")
            except Exception as e:
                print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
                print(f"‚ÑπÔ∏è  –ü–æ–ø—Ä–æ–±—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {self.model} –Ω–∞–ø—Ä—è–º—É—é...")
                
        except ImportError:
            raise ImportError(
                "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ ollama –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ollama"
            )
        except Exception as e:
            raise ConnectionError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Ollama: {e}")
    
    def analyze(
        self,
        caption: str,
        transcript: str,
        comments: List[str],
        author: str,
        known_tags: str
    ) -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ LLM
        
        Args:
            caption: –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            transcript: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
            comments: –°–ø–∏—Å–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            author: –ê–≤—Ç–æ—Ä –ø–æ—Å—Ç–∞
            known_tags: –°—Ç—Ä–æ–∫–∞ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        if self.client is None:
            self.initialize()
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        user_prompt = self._build_prompt(caption, transcript, comments, author)
        system_prompt = self.SYSTEM_PROMPT.replace("{known_tags}", known_tags)
        
        print("üß† –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        print("   ‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏...")
        
        try:
            from rich.progress import Progress, SpinnerColumn, TextColumn
            from rich.console import Console
            
            console = Console()
            
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                console=console,
                transient=True
            ) as progress:
                task = progress.add_task("   –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ AI...", total=None)
                
                response = self.client.chat(
                    model=self.model,
                    messages=[
                        {'role': 'system', 'content': system_prompt},
                        {'role': 'user', 'content': user_prompt}
                    ],
                    format='json',  # –¢—Ä–µ–±—É–µ–º JSON –æ—Ç–≤–µ—Ç
                    options={
                        'temperature': 0.7,
                        'num_predict': 1000
                    }
                )
                
                progress.update(task, completed=True)
            
            print("   ‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
            
            # –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞
            result_text = response['message']['content']
            result = json.loads(result_text)
            
            return result
            
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–û—Ç–≤–µ—Ç LLM: {result_text[:200]}...")
            return None
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ LLM: {e}")
            return None
    
    def _build_prompt(
        self,
        caption: str,
        transcript: str,
        comments: List[str],
        author: str
    ) -> str:
        """–°–±–æ—Ä–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM"""
        
        parts = [
            f"**Author:** {author}\n",
            f"**Post Caption:**\n{caption}\n" if caption else "",
            f"**Transcript:**\n{transcript}\n" if transcript else "",
        ]
        
        if comments:
            comments_text = "\n".join(f"- {c}" for c in comments[:50])  # –õ–∏–º–∏—Ç 50
            parts.append(f"**Comments:**\n{comments_text}\n")
        
        return "\n".join(filter(None, parts))
