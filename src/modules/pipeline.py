"""
Pipeline - –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Instagram –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""
from pathlib import Path
from typing import Optional
from datetime import datetime
import re
from .tag_manager import TagManager
from .hybrid_grabber import HybridGrabber
from .local_ears import LocalEars
from .local_brain import LocalBrain


class SecBrainPipeline:
    """–ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    
    def __init__(self, config: dict):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        
        Args:
            config: –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        """
        self.config = config
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π
        self.tag_manager = TagManager()
        self.grabber = HybridGrabber(
            output_dir=Path(config['temp_dir']),
            cookies_file=Path(config.get('cookies_file', 'cookies.txt'))
        )
        self.ears = LocalEars(
            model_size=config.get('whisper_model', 'base'),
            device=config.get('device', 'cpu')
        )
        self.brain = LocalBrain(
            model=config.get('ollama_model', 'llama3.2')
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ instagrapi –µ—Å–ª–∏ –µ—Å—Ç—å session
        session_file = Path(config.get('session_file', 'session.json'))
        if session_file.exists():
            self.grabber.setup_instagrapi(session_file)
    
    def process(self, url: str) -> Optional[Path]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ Instagram URL
        
        Args:
            url: URL Instagram –ø–æ—Å—Ç–∞/—Ä–∏–ª—Å–∞
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∑–∞–º–µ—Ç–∫–µ –∏–ª–∏ None
        """
        print(f"\n{'='*60}")
        print(f"üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞: {url}")
        print(f"{'='*60}\n")
        
        # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content = self.grabber.grab(url)
        if not content.media_path:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–µ–¥–∏–∞")
            return None
        
        # –®–∞–≥ 2: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è (–µ—Å–ª–∏ –≤–∏–¥–µ–æ)
        transcript_result = self.ears.transcribe(content.media_path)
        transcript_text = transcript_result.timed_transcript if transcript_result else ""
        full_text = transcript_result.full_text if transcript_result else ""
        
        # –®–∞–≥ 3: AI –∞–Ω–∞–ª–∏–∑
        known_tags_string = self.tag_manager.get_tags_string()
        
        ai_result = self.brain.analyze(
            caption=content.caption,
            transcript=transcript_text,
            comments=content.comments,
            author=content.author,
            known_tags=known_tags_string
        )
        
        if not ai_result:
            print("‚ùå –û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞")
            return None
        
        # –®–∞–≥ 4: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–≥–æ–≤
        new_tags = ai_result.get('tags', [])
        added_count = self.tag_manager.add_tags(new_tags)
        if added_count > 0:
            print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ç–µ–≥–æ–≤: {added_count}")
        
        # –®–∞–≥ 5: –°–æ–∑–¥–∞–Ω–∏–µ Asset Bundle
        print("\nüìù –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏...")
        try:
            note_path = self._create_note_bundle(
                content=content,
                ai_result=ai_result,
                transcript_text=transcript_text,
                full_text=full_text
            )
            print("   ‚úÖ –ó–∞–º–µ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–º–µ—Ç–∫–∏: {e}")
            return None
        
        print(f"\n{'='*60}")
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ó–∞–º–µ—Ç–∫–∞: {note_path}")
        print(f"{'='*60}\n")
        
        return note_path
    
    def _create_note_bundle(
        self,
        content,
        ai_result: dict,
        transcript_text: str,
        full_text: str
    ) -> Path:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ Asset Bundle (–ø–∞–ø–∫–∞ + Note.md + –º–µ–¥–∏–∞)
        
        Args:
            content: InstagramContent
            ai_result: –†–µ–∑—É–ª—å—Ç–∞—Ç AI –∞–Ω–∞–ª–∏–∑–∞
            transcript_text: –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
            full_text: –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
            
        Returns:
            –ü—É—Ç—å –∫ Note.md
        """
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏
        date_str = content.date or datetime.now().strftime("%Y-%m-%d")
        author = self._sanitize_filename(content.author or "unknown")
        slug = self._generate_slug(ai_result.get('summary', 'note'))
        
        bundle_name = f"{date_str}_{author}_{slug}"
        bundle_path = Path(self.config['output_dir']) / bundle_name
        bundle_path.mkdir(parents=True, exist_ok=True)
        
        # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –º–µ–¥–∏–∞ –≤ bundle
        media_ext = ".jpg"  # default
        if content.media_path and content.media_path.exists():
            media_ext = content.media_path.suffix
            media_dest = bundle_path / f"media{media_ext}"
            content.media_path.rename(media_dest)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Note.md
        note_content = self._generate_markdown(
            content=content,
            ai_result=ai_result,
            transcript_text=transcript_text,
            full_text=full_text,
            media_filename=f"media{media_ext}"
        )
        
        note_path = bundle_path / "Note.md"
        note_path.write_text(note_content, encoding='utf-8')
        
        return note_path
    
    def _generate_markdown(
        self,
        content,
        ai_result: dict,
        transcript_text: str,
        full_text: str,
        media_filename: str
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown –∑–∞–º–µ—Ç–∫–∏ –ø–æ —à–∞–±–ª–æ–Ω—É"""
        
        tags_yaml = "\n".join(f"  - {tag}" for tag in ai_result.get('tags', []))
        tags_yaml += "\n  - inbox"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        comments_md = ""
        for comment in ai_result.get('valuable_comments', []):
            comments_md += f"> {comment}\n\n"
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        title = f"{content.author}: {self._generate_slug(ai_result.get('summary', 'Note'))}"
        
        template = f"""---
created: {content.date or datetime.now().strftime("%Y-%m-%d")}
author: {content.author}
url: {content.url}
category: {ai_result.get('category', 'Other')}
tags:
{tags_yaml}
---

# {title}

![[{media_filename}]]

## üß† AI Summary
{ai_result.get('summary', 'No summary available')}

## üí¨ Valuable Insights (Comments)
{comments_md if comments_md else '_No valuable comments found_'}

---
<details>
<summary>üìÇ Raw Data (Transcript & Caption)</summary>

### Caption
{content.caption if content.caption else '_No caption_'}

### Transcript
{transcript_text if transcript_text else '_No transcript (image or transcription failed)_'}
</details>
"""
        return template
    
    def _sanitize_filename(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        text = re.sub(r'[^\w\s-]', '', text)
        text = re.sub(r'[-\s]+', '_', text)
        return text[:30].lower()
    
    def _generate_slug(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ slug –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫, –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
        if isinstance(text, list):
            text = text[0] if text else "note"
        # –ï—Å–ª–∏ –Ω–µ —Å—Ç—Ä–æ–∫–∞, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        if not isinstance(text, str):
            text = str(text)
        
        words = text.split()[:4]
        slug = "_".join(words)
        return self._sanitize_filename(slug)
