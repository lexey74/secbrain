#!/usr/bin/env python3
"""
SafeComments - –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ Instagram —á–µ—Ä–µ–∑ Playwright
–≠–º—É–ª–∏—Ä—É–µ—Ç –Ω–∞—Å—Ç–æ—è—â–∏–π –±—Ä–∞—É–∑–µ—Ä, –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç GraphQL –∑–∞–ø—Ä–æ—Å—ã
"""

import json
import time
import random
from pathlib import Path
from typing import List, Dict, Optional
from playwright.sync_api import sync_playwright, Page, BrowserContext


class SafeCommentsScraper:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ Instagram"""
    
    def __init__(self, cookies_file: str = "instagram_cookies.json", headless: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∞–ø–µ—Ä–∞
        
        Args:
            cookies_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å cookies
            headless: –ó–∞–ø—É—Å–∫–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ (False = –≤–∏–¥–∏–º–æ–µ –æ–∫–Ω–æ)
        """
        self.cookies_file = Path(cookies_file)
        self.headless = headless
        self.captured_data = []
        
    def _handle_response(self, response):
        """
        –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç Instagram API
        –ü–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç GraphQL –∑–∞–ø—Ä–æ—Å—ã —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
        """
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å—ã –∫ GraphQL API –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        if "graphql/query" in response.url and response.status == 200:
            try:
                data = response.json()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                if 'data' in data:
                    # –ò—â–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
                    # Instagram –∏—Å–ø–æ–ª—å–∑—É–µ—Ç edge_media_to_parent_comment –∏–ª–∏ edge_media_preview_comment
                    has_comments = self._extract_comments_from_response(data)
                    
                    if has_comments:
                        print(f"   üì¶ –ü–µ—Ä–µ—Ö–≤–∞—á–µ–Ω –ø–∞–∫–µ—Ç —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏")
                        self.captured_data.append(data)
                        
            except Exception as e:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                pass
    
    def _extract_comments_from_response(self, data: dict) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        
        Args:
            data: JSON –æ—Ç–≤–µ—Ç –æ—Ç Instagram
            
        Returns:
            True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        """
        try:
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∫–ª—é—á–µ–π —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
            def search_comments(obj):
                if isinstance(obj, dict):
                    # –ö–ª—é—á–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                    comment_keys = ['edge_media_to_parent_comment', 'edge_threaded_comments', 
                                   'edge_media_preview_comment', 'edges']
                    
                    for key in comment_keys:
                        if key in obj and 'edges' in str(obj[key]):
                            return True
                    
                    for value in obj.values():
                        if search_comments(value):
                            return True
                            
                elif isinstance(obj, list):
                    for item in obj:
                        if search_comments(item):
                            return True
                            
                return False
            
            return search_comments(data)
            
        except:
            return False
    
    def _load_cookies(self, context: BrowserContext) -> bool:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç cookies –∏–∑ —Ñ–∞–π–ª–∞
        
        Args:
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –±—Ä–∞—É–∑–µ—Ä–∞ Playwright
            
        Returns:
            True –µ—Å–ª–∏ cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ
        """
        if not self.cookies_file.exists():
            print("   ‚ö†Ô∏è  Cookies –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False
        
        try:
            with open(self.cookies_file, 'r', encoding='utf-8') as f:
                cookies = json.load(f)
                context.add_cookies(cookies)
                print("   ‚úÖ Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                return True
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ cookies: {e}")
            return False
    
    def _save_cookies(self, context: BrowserContext):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç cookies –≤ —Ñ–∞–π–ª
        
        Args:
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –±—Ä–∞—É–∑–µ—Ä–∞ Playwright
        """
        try:
            cookies = context.cookies()
            self.cookies_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(self.cookies_file, 'w', encoding='utf-8') as f:
                json.dump(cookies, f, indent=2)
                
            print("   ‚úÖ Cookies —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è cookies: {e}")
    
    def _emulate_human_behavior(self, page: Page, duration: int = 10):
        """
        –≠–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞: —Å–∫—Ä–æ–ª–ª–∏–Ω–≥, –ø–∞—É–∑—ã
        
        Args:
            page: –°—Ç—Ä–∞–Ω–∏—Ü–∞ Playwright
            duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —ç–º—É–ª—è—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        print(f"   ü§ñ –≠–º—É–ª—è—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ({duration} —Å–µ–∫)...")
        
        start_time = time.time()
        scroll_count = 0
        
        while time.time() - start_time < duration:
            # –°–ª—É—á–∞–π–Ω—ã–π —Å–∫—Ä–æ–ª–ª –≤–Ω–∏–∑
            scroll_distance = random.randint(300, 700)
            page.mouse.wheel(0, scroll_distance)
            scroll_count += 1
            
            # –°–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞
            time.sleep(random.uniform(1.5, 3.5))
            
            # –ò–Ω–æ–≥–¥–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏ –Ω–∞–∂–∞—Ç—å "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"
            if scroll_count % 3 == 0:
                try:
                    # –ò—â–µ–º –∫–Ω–æ–ø–∫–∏ –ø–æ —Ä–∞–∑–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
                    selectors = [
                        'button:has-text("View more comments")',
                        'button:has-text("Load more comments")',
                        'button[type="button"]',
                        'svg[aria-label="Load more comments"]'
                    ]
                    
                    for selector in selectors:
                        try:
                            if page.locator(selector).count() > 0:
                                page.locator(selector).first.click(timeout=1000)
                                print(f"   ‚¨áÔ∏è  –ù–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤")
                                time.sleep(random.uniform(2, 4))
                                break
                        except:
                            pass
                            
                except Exception as e:
                    pass
            
            # PageDown –∏–Ω–æ–≥–¥–∞
            if scroll_count % 5 == 0:
                page.keyboard.press("PageDown")
                time.sleep(random.uniform(1, 2))
        
        print(f"   ‚úÖ –≠–º—É–ª—è—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—Å–∫—Ä–æ–ª–ª–æ–≤: {scroll_count})")
    
    def scrape_comments(self, post_url: str, scroll_duration: int = 15) -> List[Dict]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: —Å–∫—Ä–∞–ø–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å –ø–æ—Å—Ç–∞
        
        Args:
            post_url: URL –ø–æ—Å—Ç–∞ Instagram
            scroll_duration: –°–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ —Å–∫—Ä–æ–ª–ª–∏—Ç—å (–±–æ–ª—å—à–µ = –±–æ–ª—å—à–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{'user': str, 'text': str}, ...]
        """
        print(f"üé≠ –ó–∞–ø—É—Å–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞...")
        
        self.captured_data = []
        
        with sync_playwright() as p:
            # –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ —Å –∞–Ω—Ç–∏–¥–µ—Ç–µ–∫—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            browser = p.chromium.launch(
                headless=self.headless,
                args=[
                    "--disable-blink-features=AutomationControlled",  # –°–∫—Ä—ã–≤–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é
                    "--disable-dev-shm-usage",
                    "--no-sandbox",
                    "--disable-setuid-sandbox"
                ]
            )
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            context = browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                viewport={'width': 1280, 'height': 800},
                locale='en-US',
                timezone_id='America/New_York'
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º cookies
            cookies_loaded = self._load_cookies(context)
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page = context.new_page()
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º –ø–µ—Ä–µ—Ö–≤–∞—Ç—á–∏–∫ –æ—Ç–≤–µ—Ç–æ–≤
            page.on("response", self._handle_response)
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –ø–æ—Å—Ç
            print(f"üîó –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞: {post_url}")
            page.goto(post_url, wait_until="networkidle")
            
            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
            time.sleep(random.uniform(3, 5))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –ª–æ–≥–∏–Ω
            if "login" in page.url or page.locator('input[name="username"]').count() > 0:
                print("   üîê –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è!")
                
                if not self.headless:
                    print("   ‚è≥ –í–æ–π–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é –≤ –æ—Ç–∫—Ä—ã–≤—à–µ–º—Å—è –æ–∫–Ω–µ (60 —Å–µ–∫—É–Ω–¥)...")
                    time.sleep(60)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º cookies –ø–æ—Å–ª–µ –≤—Ö–æ–¥–∞
                    self._save_cookies(context)
                else:
                    print("   ‚ùå –ù–µ –º–æ–≥—É –≤–æ–π—Ç–∏ –≤ headless —Ä–µ–∂–∏–º–µ. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ headless=False")
                    browser.close()
                    return []
            
            # –≠–º—É–ª–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞
            self._emulate_human_behavior(page, duration=scroll_duration)
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            browser.close()
        
        print(f"   üìä –ü–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–æ –ø–∞–∫–µ—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {len(self.captured_data)}")
        
        # –ü–∞—Ä—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        comments = self._parse_comments_from_captured_data()
        
        print(f"   üí¨ –ò–∑–≤–ª–µ—á–µ–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤: {len(comments)}")
        
        return comments
    
    def _parse_comments_from_captured_data(self) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã—Ö GraphQL –æ—Ç–≤–µ—Ç–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ [{'user': str, 'text': str, 'likes': int}, ...]
        """
        all_comments = []
        seen_ids = set()  # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        
        for data in self.captured_data:
            try:
                comments = self._extract_comments_recursive(data)
                
                for comment in comments:
                    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ ID
                    comment_id = comment.get('id', hash(comment['text']))
                    if comment_id not in seen_ids:
                        seen_ids.add(comment_id)
                        all_comments.append(comment)
                        
            except Exception as e:
                print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
                continue
        
        return all_comments
    
    def _extract_comments_recursive(self, obj, comments=None) -> List[Dict]:
        """
        –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        
        Args:
            obj: JSON –æ–±—ä–µ–∫—Ç
            comments: –ê–∫–∫—É–º—É–ª—è—Ç–æ—Ä –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        """
        if comments is None:
            comments = []
        
        if isinstance(obj, dict):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π?
            if 'node' in obj and isinstance(obj['node'], dict):
                node = obj['node']
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
                if 'text' in node:
                    comment = {
                        'id': node.get('id', ''),
                        'user': node.get('owner', {}).get('username', 'unknown'),
                        'text': node.get('text', ''),
                        'likes': node.get('edge_liked_by', {}).get('count', 0),
                        'created_at': node.get('created_at', 0)
                    }
                    comments.append(comment)
            
            # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è
            for value in obj.values():
                self._extract_comments_recursive(value, comments)
                
        elif isinstance(obj, list):
            for item in obj:
                self._extract_comments_recursive(item, comments)
        
        return comments
    
    def save_raw_data(self, filepath: str = "raw_comments_data.json"):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—ã—Ä—ã–µ –ø–µ—Ä–µ—Ö–≤–∞—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª
        
        Args:
            filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.captured_data, f, ensure_ascii=False, indent=2)
            print(f"   üíæ –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filepath}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    scraper = SafeCommentsScraper(
        cookies_file="instagram_cookies.json",
        headless=False  # –í–∏–¥–∏–º–æ–µ –æ–∫–Ω–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    )
    
    post_url = "https://www.instagram.com/p/EXAMPLE/"
    comments = scraper.scrape_comments(post_url, scroll_duration=15)
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
    for i, comment in enumerate(comments[:10], 1):
        print(f"{i}. {comment['user']}: {comment['text'][:50]}...")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    scraper.save_raw_data()
