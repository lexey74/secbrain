#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å 3: AI –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –æ–ø–∏—Å–∞–Ω–∏—è –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
–°–æ–∑–¥–∞–µ—Ç —Ç–µ–≥–∏, —Å–∞–º–º–∞—Ä–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ Obsidian-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π Markdown.
"""
from pathlib import Path
from typing import List, Optional, Dict
import sys
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.modules.local_brain import LocalBrain
from src.modules.tag_manager import TagManager
import threading


class AIProcessor:
    """
    –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä AI –∞–Ω–∞–ª–∏–∑–∞
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç, —Å–æ–∑–¥–∞–µ—Ç —Ç–µ–≥–∏ –∏ —Å–∞–º–º–∞—Ä–∏,
    —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ Obsidian-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç.
    """
    
    def __init__(
        self,
        content_dir: Path = Path("downloads"),
        tags_file: Path = Path("known_tags.json"),
        model: str = "qwen2.5:7b"
    ):
        """
        Args:
            content_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ø–∞–ø–∫–∞–º–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            tags_file: –§–∞–π–ª —Å –±–∞–∑–æ–π —Ç–µ–≥–æ–≤
            model: –ú–æ–¥–µ–ª—å Ollama –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        self.content_dir = Path(content_dir)
        self.brain = LocalBrain(model=model)
        self.tag_manager = TagManager(tags_file)  # –ü–µ—Ä–µ–¥–∞—ë–º –ø—É—Ç—å –Ω–∞–ø—Ä—è–º—É—é
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.image_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif']
    
    def find_content_folders(self) -> List[Path]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–∞–ø–∫–∏ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –ø–∞–ø–∫–∞–º
        """
        if not self.content_dir.exists():
            print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.content_dir}")
            return []
        
        # –°–∫–∞–Ω–∏—Ä—É–µ–º –í–°–ï –ø–∞–ø–∫–∏ –≤ downloads (–Ω–µ —Ç–æ–ª—å–∫–æ instagram/youtube)
        folders = []
        for item in self.content_dir.iterdir():
            if item.is_dir():
                folders.append(item)
        
        return sorted(folders)
    
    def has_analysis(self, folder: Path) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É–∂–µ AI –∞–Ω–∞–ª–∏–∑
        
        Args:
            folder: –ü–∞–ø–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ Knowledge.md —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        """
        note_file = folder / "Knowledge.md"
        return note_file.exists()
    
    def read_description(self, folder: Path) -> Optional[str]:
        """
        –ß–∏—Ç–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ description.md
        
        Args:
            folder: –ü–∞–ø–∫–∞ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
            
        Returns:
            –¢–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ None
        """
        desc_file = folder / "description.md"
        if desc_file.exists():
            return desc_file.read_text(encoding='utf-8')
        return None
    
    def read_transcript(self, folder: Path) -> Optional[str]:
        """
        –ß–∏—Ç–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏–∑ transcript.md
        
        Args:
            folder: –ü–∞–ø–∫–∞ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
            
        Returns:
            –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏–ª–∏ None
        """
        transcript_file = folder / "transcript.md"
        if transcript_file.exists():
            return transcript_file.read_text(encoding='utf-8')
        return None
    
    def find_images(self, folder: Path) -> List[Path]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ
        
        Args:
            folder: –ü–∞–ø–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
        """
        images = []
        for file in folder.iterdir():
            if file.is_file() and file.suffix.lower() in self.image_extensions:
                images.append(file)
        return sorted(images)
    
    def analyze_content(self, folder: Path) -> Optional[Dict]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–∞–ø–∫–∏
        
        Args:
            folder: –ü–∞–ø–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None
        """
        print(f"\nüß† AI –ê–Ω–∞–ª–∏–∑: {folder.name}")
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        description = self.read_description(folder)
        transcript = self.read_transcript(folder)
        images = self.find_images(folder)
        
        if not description and not transcript:
            print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–Ω–µ—Ç description.md –∏ transcript.md)")
            return None
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        context_parts = []
        
        if description:
            context_parts.append(f"## –û–ø–∏—Å–∞–Ω–∏–µ\n\n{description}")
        
        if transcript:
            context_parts.append(f"## –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è\n\n{transcript}")
        
        if images:
            context_parts.append(f"## –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(images)}")
        
        context = "\n\n".join(context_parts)
        
        # AI –∞–Ω–∞–ª–∏–∑
        try:
            print("   ü§ñ –ó–∞–ø—É—Å–∫ AI –∞–Ω–∞–ª–∏–∑–∞...")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
            known_tags_str = self.tag_manager.get_tags_string()
            
            # –°–æ–∑–¥–∞–µ–º —Å–∞–º–º–∞—Ä–∏
            summary = self.brain.analyze(
                caption=description or "",
                transcript=transcript or "",
                comments=[],  # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
                author="",     # –ê–≤—Ç–æ—Ä –Ω–µ –≤—Å–µ–≥–¥–∞ –∏–∑–≤–µ—Å—Ç–µ–Ω
                known_tags=known_tags_str
            )
            
            if not summary:
                print("‚ùå AI –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ AI (summary —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–≥–∏)
            print("   üè∑Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–≥–æ–≤...")
            tags = summary.get('tags', [])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ç–µ–≥–∏ –≤ –±–∞–∑—É
            new_count = 0
            if tags:
                new_count = self.tag_manager.add_tags(tags)
                if new_count > 0:
                    print(f"   ‚ú® –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ç–µ–≥–æ–≤: {new_count}")
                print(f"   ‚úÖ –¢–µ–≥–∏: {', '.join(tags)}")
            else:
                print("   ‚ö†Ô∏è  –¢–µ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
            return {
                'summary': summary,
                'tags': tags,
                'new_tags_count': new_count,
                'has_description': description is not None,
                'has_transcript': transcript is not None,
                'image_count': len(images)
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_summary_text(self, summary_data: Dict) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å–∞–º–º–∞—Ä–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ LLM.
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞.
        
        Args:
            summary_data: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç LLM
            
        Returns:
            –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–∞–º–º–∞—Ä–∏
        """
        if not isinstance(summary_data, dict):
            return str(summary_data)
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {'summary': '...', 'category': '...', ...}
        if 'summary' in summary_data:
            return summary_data['summary']
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å key_points
        if 'key_points' in summary_data:
            parts = []
            if 'video_title' in summary_data:
                parts.append(f"**{summary_data['video_title']}**\n")
            
            key_points = summary_data['key_points']
            if isinstance(key_points, list):
                parts.append('\n'.join(f"- {point}" for point in key_points))
            else:
                parts.append(str(key_points))
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'total_time' in summary_data:
                parts.append(f"\n**–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã:** {summary_data['total_time']}")
            if 'cost_without_lighting' in summary_data:
                parts.append(f"**–°—Ç–æ–∏–º–æ—Å—Ç—å:** {summary_data['cost_without_lighting']}")
            
            return '\n'.join(parts)
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥–æ—à–ª–æ, —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∫ —Å–ø–∏—Å–æ–∫ –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
        result_parts = []
        for key, value in summary_data.items():
            if key in ('tags', 'valuable_comments', 'category'):
                continue  # –≠—Ç–∏ –ø–æ–ª—è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
            if isinstance(value, list):
                result_parts.append(f"**{key}:**")
                for item in value:
                    result_parts.append(f"- {item}")
            elif isinstance(value, dict):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏
            else:
                result_parts.append(f"**{key}:** {value}")
        
        return '\n'.join(result_parts) if result_parts else '–ù–µ—Ç —Å–∞–º–º–∞—Ä–∏'
    
    def create_obsidian_note(
        self, 
        folder: Path, 
        analysis: Dict
    ) -> Optional[Path]:
        """
        –°–æ–∑–¥–∞–µ—Ç Knowledge.md –≤ —Ñ–æ—Ä–º–∞—Ç–µ Obsidian
        
        Args:
            folder: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
        """
        note_file = folder / "Knowledge.md"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏
        folder_name = folder.name
        # –§–æ—Ä–º–∞—Ç: –∏—Å—Ç–æ—á–Ω–∏–∫_ID_–Ω–∞–∑–≤–∞–Ω–∏–µ
        parts = folder_name.split('_', 2)
        title = parts[2] if len(parts) > 2 else folder_name
        title = title.replace('_', ' ')
        
        # –°–æ–∑–¥–∞–µ–º Obsidian frontmatter
        tags_str = ', '.join(analysis['tags'])
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ summary
        summary_data = analysis['summary']
        summary_text = self._extract_summary_text(summary_data)
        category = summary_data.get('category', '–ù–µ —É–∫–∞–∑–∞–Ω–∞') if isinstance(summary_data, dict) else '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
        
        markdown = f"""---
title: {title}
date: {datetime.now().strftime('%Y-%m-%d')}
tags: [{', '.join(f'#{tag}' for tag in analysis['tags'])}]
source: {parts[0] if len(parts) > 0 else 'unknown'}
processed: true
---

# {title}

## üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

- **–ò—Å—Ç–æ—á–Ω–∏–∫**: {parts[0].upper() if len(parts) > 0 else 'UNKNOWN'}
- **ID**: {parts[1] if len(parts) > 1 else 'unknown'}
- **–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
- **–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**: {analysis['image_count']}
- **–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è**: {'‚úÖ' if analysis['has_transcript'] else '‚ùå'}

## üè∑Ô∏è –¢–µ–≥–∏

{' '.join(f'#{tag}' for tag in analysis['tags'])}

## üìù –°–∞–º–º–∞—Ä–∏

{summary_text}

## üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è

{category}

## üí¨ –¶–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏

"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ü–µ–Ω–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if isinstance(analysis['summary'], dict) and analysis['summary'].get('valuable_comments'):
            for comment in analysis['summary']['valuable_comments']:
                markdown += f"- {comment}\n"
        else:
            markdown += "*–ù–µ—Ç —Ü–µ–Ω–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤*\n"
        
        markdown += "\n## üìé –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n\n- [[description.md|–û–ø–∏—Å–∞–Ω–∏–µ]]\n"
        
        if analysis['has_transcript']:
            markdown += "- [[transcript.md|–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è]]\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if analysis['image_count'] > 0:
            markdown += "\n## üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n\n"
            images = self.find_images(folder)
            for i, img in enumerate(images, 1):
                markdown += f"![[{img.name}]]\n"
        
        markdown += "\n---\n\n*–°–æ–∑–¥–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–æ–¥—É–ª–µ–º AI –∞–Ω–∞–ª–∏–∑–∞ [SecondBrain](https://t.me/sec_brainbot)*\n"
        
        try:
            note_file.write_text(markdown, encoding='utf-8')
            print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: Knowledge.md")
            # –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤ RAG (–µ—Å–ª–∏ –º–æ–¥—É–ª—å –¥–æ—Å—Ç—É–ø–µ–Ω)
            try:
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ª–µ–Ω–∏–≤–æ ‚Äî –µ—Å–ª–∏ –º–æ–¥—É–ª—å4 –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
                from src.modules.module4_rag import RAGEngine

                try:
                    # –ò—â–µ–º –∫–æ—Ä–µ–Ω—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä downloads/{user_folder})
                    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ –ø–∞–ø–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ª–µ–∂–∏—Ç –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    user_root = None
                    for p in note_file.parents:
                        if p.name and (p.parent.name == 'downloads' or '_' in p.name or p.parent == Path('downloads')):
                            user_root = p
                            break

                    rag = RAGEngine(user_root=user_root)
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ–Ω–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫
                    def _run_index():
                        try:
                            indexed = rag.index_folder(folder)
                            print(f"   ‚úÖ Indexed {indexed} chunks into user's RAG DB")
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è RAG indexing failed (background): {e}")

                    t = threading.Thread(target=_run_index, daemon=True)
                    t.start()
                except Exception as e:
                    print(f"   ‚ö†Ô∏è RAG indexing failed: {e}")
            except ImportError:
                # module4 not installed ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                pass

            return note_file
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return None
    
    def should_process_folder(self, folder: Path) -> tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–∞ –ª–∏ AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø–∞–ø–∫–∏
        
        –õ–æ–≥–∏–∫–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó:
        - SKIP –µ—Å–ª–∏ Knowledge.md —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        - SKIP –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ, –Ω–æ –Ω–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–∂–¥—ë–º –ú–æ–¥—É–ª—å 2)
        - PROCESS –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ + —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
        - PROCESS –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Ñ–æ—Ç–æ/—Ç–µ–∫—Å—Ç (–±–µ–∑ –∞—É–¥–∏–æ) + description.md
        
        Args:
            folder: –ü–∞–ø–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            (–Ω—É–∂–Ω–∞_–æ–±—Ä–∞–±–æ—Ç–∫–∞, –ø—Ä–∏—á–∏–Ω–∞)
        """
        # 1. –ï—Å–ª–∏ –µ—Å—Ç—å Knowledge.md - —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞
        if self.has_analysis(folder):
            return False, "Knowledge.md —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –í–ò–î–ï–û/–ê–£–î–ò–û —Ñ–∞–π–ª–æ–≤ (–ù–ï —Ñ–æ—Ç–æ!)
        # –§–æ—Ç–æ –Ω–µ —Ç—Ä–µ–±—É—é—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Å—Ä–∞–∑—É
        video_audio_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.mp3', '.m4a', '.wav', '.flac', '.ogg']
        video_audio_files = [
            f for f in folder.iterdir() 
            if f.is_file() and f.suffix.lower() in video_audio_extensions
        ]
        
        has_transcript = (folder / "transcript.md").exists()
        has_description = (folder / "description.md").exists()
        
        # 3. –ï—Å–ª–∏ –µ—Å—Ç—å –í–ò–î–ï–û/–ê–£–î–ò–û —Ñ–∞–π–ª—ã
        if video_audio_files:
            # –ù—É–∂–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å–Ω–∞—á–∞–ª–∞
            if not has_transcript:
                return False, "–µ—Å—Ç—å –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ, –Ω–æ –Ω–µ—Ç transcript.md (—Ç—Ä–µ–±—É–µ—Ç—Å—è –ú–æ–¥—É–ª—å 2)"
            # –ï—Å—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è - –º–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
            return True, "–µ—Å—Ç—å –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ + transcript.md"
        
        # 4. –ï—Å–ª–∏ –ù–ï–¢ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ (—Ç–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –∏–ª–∏ —Ç–µ–∫—Å—Ç)
        if has_description:
            # –¢–µ–∫—Å—Ç–æ–≤–∞—è –∑–∞–º–µ—Ç–∫–∞ –∏–ª–∏ —Ñ–æ—Ç–æ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º - –º–æ–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Å—Ä–∞–∑—É
            return True, "–µ—Å—Ç—å description.md (—Ñ–æ—Ç–æ/—Ç–µ–∫—Å—Ç –±–µ–∑ –∞—É–¥–∏–æ)"
        
        # 5. –í–æ–æ–±—â–µ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        return False, "–Ω–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    
    def _process_content_folder(self, folder: Path) -> dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É –ø–∞–ø–∫—É
        
        Args:
            folder: –ü–∞–ø–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        stats = {
            'folder': folder.name,
            'already_processed': False,
            'success': False,
            'new_tags': 0,
            'error': None,
            'skip_reason': None
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        should_process, reason = self.should_process_folder(folder)
        
        if not should_process:
            print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫: {folder.name} ({reason})")
            if "Knowledge.md —Å—É—â–µ—Å—Ç–≤—É–µ—Ç" in reason:
                stats['already_processed'] = True
            else:
                stats['skip_reason'] = reason
            return stats
        
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞: {folder.name} ({reason})")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        analysis = self.analyze_content(folder)
        
        if not analysis:
            stats['error'] = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"
            return stats
        
        # –°–æ–∑–¥–∞–µ–º Knowledge.md
        note_file = self.create_obsidian_note(folder, analysis)
        
        if note_file:
            stats['success'] = True
            stats['new_tags'] = analysis.get('new_tags_count', 0)
        else:
            stats['error'] = "–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Knowledge.md"
        
        return stats
    
    def process_folder(self, folder: Path) -> dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–∞–ø–∫—É (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ, –µ—Å–ª–∏ —ç—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–≥–ª—è–¥–∏—Ç –ª–∏ –ø–∞–ø–∫–∞ –∫–∞–∫ –∫–æ–Ω—Ç–µ–Ω—Ç
        should, reason = self.should_process_folder(folder)
        
        # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ–Ω—Ç–µ–Ω—Ç (–∏–ª–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç)
        is_content = should or "Knowledge.md" in reason or "—Ç—Ä–µ–±—É–µ—Ç—Å—è –ú–æ–¥—É–ª—å 2" in reason
        
        if is_content:
            return self._process_content_folder(folder)
            
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º —Ä–µ–∫—É—Ä—Å–∏—é
        try:
            subfolders = [f for f in folder.iterdir() if f.is_dir()]
        except Exception:
            subfolders = []
            
        if not subfolders:
            # –ù–µ—Ç –ø–æ–¥–ø–∞–ø–æ–∫ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –¥–ª—è –ø—É—Å—Ç–æ–π –ø–∞–ø–∫–∏
            return self._process_content_folder(folder)
            
        print(f"üìÇ –ü–∞–ø–∫–∞ {folder.name} ‚Äî –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(subfolders)} –ø–æ–¥–ø–∞–ø–æ–∫...")
        
        agg_stats = {
            'folder': folder.name,
            'success': False,
            'already_processed': False,
            'new_tags': 0,
            'success_count': 0,
            'error': None
        }
        
        for sub in subfolders:
            if sub.name.startswith('.'): continue
            
            sub_stats = self.process_folder(sub)
            
            if sub_stats.get('success'):
                agg_stats['success'] = True
                agg_stats['success_count'] += 1
                agg_stats['new_tags'] += sub_stats.get('new_tags', 0)
            elif sub_stats.get('already_processed'):
                agg_stats['already_processed'] = True
                
        if agg_stats['success']:
             print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {agg_stats['success_count']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ {folder.name}")
             
        return agg_stats

    def process_all(self) -> dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –ø–∞–ø–∫–∏
        
        Returns:
            –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        print("\n" + "="*70)
        print("üß† –ú–û–î–£–õ–¨ 3: AI –ê–ù–ê–õ–ò–ó")
        print("="*70)
        print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.content_dir}")
        print(f"üè∑Ô∏è  –ë–∞–∑–∞ —Ç–µ–≥–æ–≤: {self.tag_manager.tags_file}")
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–∞–ø–∫–∏
        folders = self.find_content_folders()
        
        if not folders:
            print("\n‚ö†Ô∏è  –ü–∞–ø–∫–∏ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return {'total_folders': 0}
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫: {len(folders)}")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_stats = {
            'total_folders': len(folders),
            'already_processed': 0,
            'successfully_processed': 0,
            'need_transcription': 0,
            'no_content': 0,
            'errors': 0,
            'total_new_tags': 0
        }
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É
        for i, folder in enumerate(folders, 1):
            print(f"\n{'='*70}")
            print(f"üìÇ [{i}/{len(folders)}] {folder.name}")
            print(f"{'='*70}")
            
            stats = self.process_folder(folder)
            
            if stats['already_processed']:
                total_stats['already_processed'] += 1
            elif stats['success']:
                total_stats['successfully_processed'] += 1
                total_stats['total_new_tags'] += stats['new_tags']
            elif stats.get('skip_reason'):
                reason = stats['skip_reason']
                if "—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è" in reason:
                    total_stats['need_transcription'] += 1
                elif "–Ω–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞" in reason:
                    total_stats['no_content'] += 1
            else:
                total_stats['errors'] += 1
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "="*70)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("="*70)
        print(f"–í—Å–µ–≥–æ –ø–∞–ø–æ–∫: {total_stats['total_folders']}")
        print(f"–£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (Knowledge.md): {total_stats['already_processed']}")
        print(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_stats['successfully_processed']}")
        print(f"–ù–æ–≤—ã—Ö —Ç–µ–≥–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {total_stats['total_new_tags']}")
        
        if total_stats['need_transcription'] > 0:
            print(f"‚è≥ –¢—Ä–µ–±—É—é—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {total_stats['need_transcription']}")
        if total_stats['no_content'] > 0:
            print(f"‚ö†Ô∏è  –ù–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {total_stats['no_content']}")
        if total_stats['errors'] > 0:
            print(f"‚ùå –û—à–∏–±–æ–∫: {total_stats['errors']}")
        print("="*70)
        
        return total_stats


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="–ú–æ–¥—É–ª—å 3: AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"
    )
    parser.add_argument(
        '--dir',
        type=Path,
        default=Path('downloads'),
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: downloads)'
    )
    parser.add_argument(
        '--tags',
        type=Path,
        default=Path('known_tags.json'),
        help='–§–∞–π–ª —Å –±–∞–∑–æ–π —Ç–µ–≥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: known_tags.json)'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='qwen2.5:7b',
        help='–ú–æ–¥–µ–ª—å Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: qwen2.5:7b)'
    )
    parser.add_argument(
        '--folder',
        type=str,
        help='–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –ø–∞–ø–∫—É (–∏–º—è –ø–∞–ø–∫–∏)'
    )
    
    args = parser.parse_args()
    
    processor = AIProcessor(
        content_dir=args.dir,
        tags_file=args.tags,
        model=args.model
    )
    
    if args.folder:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏
        folder_path = args.dir / args.folder
        if not folder_path.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
            sys.exit(1)
        
        print(f"\nüéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏: {args.folder}")
        stats = processor.process_folder(folder_path)
        
        print("\n" + "="*70)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("="*70)
        if stats['already_processed']:
            print("‚è≠Ô∏è  –ü–∞–ø–∫–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
        elif stats['success']:
            print("‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            if stats['new_tags'] > 0:
                print(f"‚ú® –ù–æ–≤—ã—Ö —Ç–µ–≥–æ–≤: {stats['new_tags']}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {stats['error']}")
    else:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–∞–ø–æ–∫
        processor.process_all()


if __name__ == "__main__":
    main()
